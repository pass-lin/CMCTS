# -*- coding: utf-8 -*-
"""
Created on Sun Jul 28 15:45:07 2024

@author: Administrator
"""

import os
from transformers import AutoTokenizer
import numpy as np
import gc
from vllm import LLM, SamplingParams
import difflib
import re
from copy import deepcopy
from wrapt_timeout_decorator import timeout


@timeout(1)
def execute(a, b):
    exec(a, b)


def find_closest(str1, str_list):
    # åˆ›å»ºSequenceMatcherå¯¹è±¡
    seq_match = difflib.SequenceMatcher()
    seq_match.set_seq1(str1)

    # åˆå§‹åŒ–æœ€æ¥è¿‘çš„å­—ç¬¦ä¸²å’Œæœ€å¤§åŒ¹é…åº¦
    closest_str = None
    max_ratio = 0

    # éå†å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ‰¾åˆ°åŒ¹é…åº¦æœ€é«˜çš„å­—ç¬¦ä¸²
    for s in str_list:
        seq_match.set_seq2(s)
        ratio = seq_match.ratio()
        if ratio > max_ratio:
            max_ratio = ratio
            closest_str = s

    return closest_str, max_ratio


def get_deberta_retrieval_model(
    logits_config_path, logits_weights_path, logits_dict_path
):
    """
    åˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªDeBERTaæ¨¡å‹ç”¨äºæ£€ç´¢ä»»åŠ¡ï¼Œä»¥åŠç›¸åº”çš„tokenizerã€‚

    å‚æ•°:
    - logits_config_path (str): DeBERTaæ¨¡å‹é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚
    - logits_weights_path (str): DeBERTaæ¨¡å‹æƒé‡æ–‡ä»¶çš„è·¯å¾„ã€‚
    - logits_dict_path (str): è¯æ±‡è¡¨æ–‡ä»¶çš„è·¯å¾„ï¼Œç”¨äºåˆå§‹åŒ–tokenizerã€‚

    è¿”å›:
    - encoder (keras.Model): ç”¨äºæ£€ç´¢ä»»åŠ¡çš„DeBERTaæ¨¡å‹ã€‚
    - tokenizer (SpTokenizer): ç”¨äºæ–‡æœ¬tokenåŒ–çš„tokenizerã€‚
    """

    import keras
    from bert4keras3.tokenizers import SpTokenizer
    from bert4keras3.layers import GlobalAveragePooling1D
    from bert4keras3.models import build_transformer_model

    dtype = keras.config.dtype_policy()
    keras.config.set_dtype_policy("float32")
    tokenizer = SpTokenizer(logits_dict_path)

    deberta = build_transformer_model(
        config_path=logits_config_path,
        keras_weights_path=logits_weights_path,
        model="deberta",
        return_keras_model=True,
        dropout_rate=0.3,
        with_mlm=False,
    )
    mask = deberta.get_layer("Padding-Mask").output

    z1 = GlobalAveragePooling1D(name="Pooling-Last")(deberta.output[0], mask=mask[:, 0])
    z2 = GlobalAveragePooling1D(name="Pooling-First")(
        deberta.get_layer("Transformer-0-FeedForward-Norm").output, mask=mask[:, 0]
    )
    encoder = keras.Model(deberta.inputs, (z1 + z2) / 2)
    keras.config.set_dtype_policy(dtype)
    encoder.compile(jit_compile=True)
    return encoder, tokenizer


max_output_str = 256


def eval_trajectory(trajectory):
    question = trajectory.split("\n")[0].split(":")[-1].split(",")[-1]
    states = trajectory.split("\n")
    if len(states) % 2 == 0:
        return False
    while states[-1] == "":
        states.pop(-1)
    for j in range(1, len(states) - 4, 2):
        distance = difflib.SequenceMatcher(
            None, states[j].split(":")[1], question
        ).ratio()
        if distance > 0.8:
            return True
    return False


def eval_quality_rule(trajectory, config):
    trajectory_lits = trajectory.split("\n")
    if len(trajectory[:-1].split("\n")) % 2 == 0:
        return False

    for t in trajectory_lits[1:-1]:
        if config.answer_prefix + " {idx}." in t:
            if t.lower().count(config.answer_prefix.lower()) == 1:
                return False
    return not eval_trajectory(trajectory)


class GenerateModel:
    def __init__(
        self,
        model_name: str,
        temperature=1,
        top_p: float = 0.7,
        max_tokens: int = 256,
        top_k: int = 50,
        stop: list = ["\n"],
        stop_token_ids=None,
        select_tokens=[" Yes", " No"],
        gpu_memory_utilization=0.9,
        enable_lora=False,
        reward_model=None,
        max_generate_model_len=None,
        max_model_len=None,
        use_tqdm=True,
    ):
        self.use_tqdm = use_tqdm
        if stop_token_ids is None:
            if "qwen" in model_name.lower():
                stop_token_ids = [151645, 151643]
            elif "yi" in model_name.lower():
                stop_token_ids = [1, 2]
            elif "llama-3.1" in model_name.lower():
                stop_token_ids = [128000, 128040]
            elif "llama-3.2" in model_name.lower():
                stop_token_ids = [128000, 128001, 128008, 128009]
            elif "llama-2" in model_name.lower():
                stop_token_ids = [1, 2]
            elif "mistral" in model_name.lower():
                stop_token_ids = [1, 2]
            elif "glm" in model_name.lower():
                stop_token_ids = [151329, 151336, 151338]
        self.select_tokens = select_tokens
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name, trust_remote_code=True
        )
        self.max_model_len = max_model_len
        self.max_generate_model_len = (
            max_generate_model_len
            if max_generate_model_len is not None
            else max_model_len
        )
        self.model = LLM(
            model=model_name,
            gpu_memory_utilization=gpu_memory_utilization,
            enable_prefix_caching=True,
            trust_remote_code=True,
            max_model_len=self.max_generate_model_len,
            enable_lora=enable_lora,
            tensor_parallel_size=len(os.environ["CUDA_VISIBLE_DEVICES"].split(",")),
        )
        self.temperature = temperature
        self.top_p = top_p
        if reward_model == None:
            self.reward_model = self.model
        else:
            self.reward_model = reward_model
        self.max_tokens = max_tokens
        self.top_k = top_k
        self.stop_token_ids = stop_token_ids
        self.stop = stop
        self.select_token_id = [
            self.tokenizer.encode(select_token)[-1] for select_token in select_tokens
        ]

    def get_logis(self, logit_dict: dict, token: int):
        if token not in logit_dict.keys():
            # print('not find token at top20')
            return -1e9
        return logit_dict[token].logprob

    def rewards_predict(self, reward_inputs, select_token_id=None):
        if select_token_id is None:
            select_token_id = self.select_token_id
        inputs = []
        indicis = []
        for i, nodes in enumerate(reward_inputs):
            for node in nodes:
                indicis.append(i)
                inputs.append(node)
        results = self.reward_model.generate(
            inputs,
            SamplingParams(
                top_p=1,
                max_tokens=1,
                logprobs=20,
            ),
            use_tqdm=self.use_tqdm,
        )
        logits_output = [[] for i in range(len(reward_inputs))]
        for i, result in enumerate(results):
            try:
                logit_dict = result.outputs[0].logprobs[0]
                logits = [self.get_logis(logit_dict, id) for id in select_token_id]
            except:
                logits = [1, 1]
            logits_output[indicis[i]].append(logits)
        return logits_output

    def generate_actions(
        self,
        action_inputs,
        n_action=1,
        out_prefix="\n",
        stop=None,
        temperature=None,
        top_p=None,
        top_k=None,
    ):
        if stop is None:
            stop = self.stop
        if temperature is None:
            temperature = self.temperature
        if top_p is None:
            top_p = self.top_p
        if top_k is None:
            top_k = self.top_k
        generate_result = self.model.generate(
            action_inputs,
            SamplingParams(
                temperature=temperature,
                top_p=top_p,
                max_tokens=self.max_tokens,
                n=n_action,
                top_k=top_k,
                stop=stop,
                stop_token_ids=(self.stop_token_ids),
            ),
            use_tqdm=self.use_tqdm,
        )
        outputs = []
        for result in generate_result:
            for t in result.outputs:
                outputs.append(t.text + out_prefix)
        return outputs

    def generate(self, model_inputs, flags, states, middle_results, n_action: int = 1):
        action_inputs, action_indexs = [], []
        step_inputs, step_indexs = [], []
        reward_inputs, reward_indexs = [], []
        question_inputs, question_indexs = [], []
        for i in range(len(states)):
            if states[i] == None or flags[i] == False:
                continue
            elif states[i] == "Search_End":
                flags[i] = False
            elif "end" in states[i].lower():
                continue
            elif "fast_reward" == states[i]:
                reward_inputs.append(model_inputs[i])
                reward_indexs.append(i)
            elif "get_question" == states[i]:
                question_inputs.append(model_inputs[i])
                question_indexs.append(i)
            elif "get_action" == states[i]:
                action_inputs.append(model_inputs[i])
                action_indexs.append(i)
            elif "step" == states[i]:
                step_inputs.append(model_inputs[i])
                step_indexs.append(i)
        if len(action_inputs) != 0:
            print("generate action")
            actions = self.generate_actions(action_inputs, n_action)
            for i, index in enumerate(action_indexs):
                middle_results[index].action_outputs = actions[
                    i * n_action : (i + 1) * n_action
                ]

        if len(reward_inputs) != 0:
            print("generate rewards")
            logits = self.rewards_predict(reward_inputs)

            for i, index in enumerate(reward_indexs):
                middle_results[index].logits = logits[i]
        if len(step_inputs) != 0:
            print("generate states")
            inputs = []
            for i, t in enumerate(step_inputs):
                inputs.extend(t)
            steps = self.generate_actions(inputs)
            outputs = [[] for i in range(len(step_inputs))]
            k = 0
            for i in range(len(step_inputs)):
                for j in range(len(step_inputs[i])):
                    outputs[i].append(steps[k])
                    k += 1
            for i, index in enumerate(step_indexs):
                middle_results[index].step_outputs = outputs[i]

        if len(question_inputs) != 0:
            print("generate question")
            inputs = []
            for i, t in enumerate(question_inputs):
                inputs.extend(t)
            questions = self.generate_actions(inputs)
            outputs = [[] for i in range(len(question_inputs))]
            k = 0
            for i in range(len(question_inputs)):
                for j in range(len(question_inputs[i])):
                    outputs[i].append(questions[k])
                    k += 1
            for i, index in enumerate(question_indexs):
                middle_results[index].questions = outputs[i]
        gc.collect()


class ChatGenerateModel(GenerateModel):
    def __init__(
        self,
        model_name: str,
        prompt=None,
        max_tokens=768,
        code_topp=0.1,
        code_topk=1024,
        code_temperature=1,
        **kwargs,
    ):
        super().__init__(model_name=model_name, max_tokens=max_tokens, **kwargs)
        self.prompt = prompt
        self.code_topp = code_topp
        self.code_topk = code_topk
        self.code_temperature = code_temperature

    def chat_generate(
        self,
        inputs,
        prefix="",
        n: int = 1,
        out_put_add_prefix: bool = True,
        stop=None,
        temperature=None,
        top_p=None,
        top_k=None,
        max_tokens=None,
    ):
        """
        æ ¹æ®è¾“å…¥ç”ŸæˆèŠå¤©å›å¤ã€‚

        :param inputs: ç”¨æˆ·çš„è¾“å…¥ï¼Œå¯ä»¥æ˜¯å•ä¸ªè¾“å…¥æˆ–è¾“å…¥åˆ—è¡¨ã€‚
        :param prefix: ç”Ÿæˆæ–‡æœ¬å‰æ·»åŠ çš„å‰ç¼€ã€‚
        :param n: ç”Ÿæˆçš„å›å¤æ•°é‡ã€‚
        :param out_put_add_prefix: æ˜¯å¦åœ¨è¾“å‡ºä¸­æ·»åŠ å‰ç¼€ã€‚
        :param stop: åœæ­¢ç”Ÿæˆçš„æ¡ä»¶ã€‚
        :param temperature: ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ã€‚
        :param top_p: æ ¸é‡‡æ ·çš„æ¯”ä¾‹ã€‚
        :param top_k: ä»å¤šå°‘ä¸ªå€™é€‰è¯ä¸­é€‰æ‹©ä¸‹ä¸€ä¸ªè¯ã€‚
        :return: ç”Ÿæˆçš„èŠå¤©å›å¤åˆ—è¡¨ã€‚
        """

        # ç¡®ä¿è¾“å…¥æ˜¯ä¸€ä¸ªåˆ—è¡¨
        if not isinstance(inputs[0], list):
            inputs = [inputs]
        # åº”ç”¨èŠå¤©æ¨¡æ¿å¹¶æ·»åŠ ç”Ÿæˆæç¤º
        chat_inputs = []
        for t in inputs:
            if t[-1]["role"] == "user":
                chat_inputs.append(
                    self.tokenizer.apply_chat_template(
                        t, tokenize=False, add_generation_prompt=True
                    )
                    + prefix
                )
            else:
                chat_inputs.append(
                    self.tokenizer.apply_chat_template(
                        t, tokenize=False, add_generation_prompt=False
                    )[:-11]
                    + prefix
                )

        # ä½¿ç”¨ç±»åˆå§‹åŒ–æ—¶è®¾ç½®çš„é»˜è®¤å‚æ•°å€¼ï¼Œå¦‚æœæœªæä¾›
        if temperature is None:
            temperature = self.temperature
        if top_p is None:
            top_p = self.top_p
        if top_k is None:
            top_k = self.top_k

        # ç”Ÿæˆå›å¤
        generate_result = self.model.generate(
            chat_inputs,
            SamplingParams(
                temperature=temperature,
                top_p=top_p,
                max_tokens=self.max_tokens if max_tokens == None else max_tokens,
                n=n,
                top_k=top_k,
                stop=stop,
                stop_token_ids=(self.stop_token_ids),
            ),
            use_tqdm=self.use_tqdm,
        )

        # å¤„ç†ç”Ÿæˆç»“æœï¼Œæ„å»ºè¾“å‡ºæ ¼å¼
        outputs = []
        for i, result in enumerate(generate_result):
            for t in result.outputs:
                if inputs[i][-1]["role"] == "user":
                    if out_put_add_prefix:
                        outputs.append(
                            {"role": "assistant", "content": prefix + t.text}
                        )
                    else:
                        outputs.append({"role": "assistant", "content": t.text})
                else:
                    out = inputs[i][-1]["content"] + t.text
                    outputs.append({"role": "assistant", "content": out})

        return outputs

    def generate_code(
        self,
        inputs,
        eval_function=None,
        prefix: str = "```python",
        stop: str = "```",
        flags=None,
        outputs=None,
        iter_num=3,
        show_code=False,
    ):
        """
        ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ã€‚

        æœ¬å‡½æ•°å°è¯•ä¸ºæ¯ä¸ªè¾“å…¥ç”Ÿæˆä»£ç å¹¶æ‰§è¡Œï¼Œç›´åˆ°æ‰€æœ‰è¾“å…¥éƒ½æˆåŠŸæˆ–å°è¯•æ¬¡æ•°è¾¾åˆ°æœ€å¤§å€¼ã€‚

        å‚æ•°:
        - inputs: ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦ç”Ÿæˆä»£ç çš„è¾“å…¥ã€‚
        - eval_function: ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè¯„ä¼°ç”Ÿæˆçš„ä»£ç ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™ä¸è¿›è¡Œè¯„ä¼°ã€‚
        - prefix: ä»£ç å‰ç¼€ï¼Œé»˜è®¤ä¸º'```python'ã€‚
        - stop: ä»£ç ç»“æŸæ ‡å¿—ï¼Œé»˜è®¤ä¸º'```'ã€‚
        - flags: ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºè·Ÿè¸ªæ¯ä¸ªè¾“å…¥çš„å®ŒæˆçŠ¶æ€ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™åˆå§‹åŒ–ä¸ºæ‰€æœ‰è¾“å…¥çš„Trueåˆ—è¡¨ã€‚
        - outputs: ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªè¾“å…¥çš„æ‰§è¡Œç»“æœã€‚å¦‚æœä¸ºNoneï¼Œåˆ™åˆå§‹åŒ–ä¸ºæ‰€æœ‰è¾“å…¥çš„[None,None]åˆ—è¡¨ã€‚

        è¿”å›:
        - outputs: ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰è¾“å…¥çš„æ‰§è¡Œç»“æœã€‚
        - flags: ä¸€ä¸ªåˆ—è¡¨ï¼Œè¡¨ç¤ºæ¯ä¸ªè¾“å…¥æ˜¯å¦æˆåŠŸç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ã€‚
        """

        # åˆå§‹åŒ–æ ‡å¿—åˆ—è¡¨ï¼Œç”¨äºè·Ÿè¸ªæ¯ä¸ªè¾“å…¥çš„å®ŒæˆçŠ¶æ€
        if flags is None:
            flags = [True] * len(inputs)
        # æ·±æ‹·è´è¾“å…¥åˆ—è¡¨ï¼Œä»¥é¿å…ä¿®æ”¹åŸå§‹è¾“å…¥
        inputs = [deepcopy(t) for t in inputs]
        # åˆå§‹åŒ–è¾“å‡ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨æ¯ä¸ªè¾“å…¥çš„æ‰§è¡Œç»“æœ
        if outputs is None:
            outputs = [[None, None] for i in range(len(inputs))]
        # æœ€å¤šå°è¯•ç”Ÿæˆä»£ç å¹¶æ‰§è¡Œ3æ¬¡
        for iter in range(iter_num):
            # å¦‚æœæ‰€æœ‰è¾“å…¥éƒ½å·²å®Œæˆï¼Œè·³å‡ºå¾ªç¯
            if not any(flags):
                break
            # åˆå§‹åŒ–æœ¬æ¬¡å¾ªç¯çš„ä»£ç è¾“å…¥åˆ—è¡¨å’Œç´¢å¼•åˆ—è¡¨
            code_inputs = []
            indexs = []
            # éå†è¾“å…¥åˆ—è¡¨ï¼Œå°†æœªå®Œæˆçš„è¾“å…¥æ·»åŠ åˆ°æœ¬æ¬¡å¾ªç¯çš„ä»£ç è¾“å…¥åˆ—è¡¨ä¸­
            for i in range(len(inputs)):
                if flags[i]:
                    code_inputs.append(inputs[i])
                    indexs.append(i)
            # è°ƒç”¨èŠå¤©ç”Ÿæˆå‡½æ•°ï¼Œç”Ÿæˆä»£ç 
            code_results = self.chat_generate(
                code_inputs,
                temperature=self.code_temperature,
                top_k=self.code_topk,
                top_p=self.code_topp,
                prefix=prefix,
                stop=stop,
                out_put_add_prefix=False,
            )
            # éå†ç”Ÿæˆçš„ä»£ç ç»“æœï¼Œæ‰§è¡Œä»£ç å¹¶æ›´æ–°è¾“å‡ºåˆ—è¡¨å’Œæ ‡å¿—åˆ—è¡¨
            for result_index, inputs_index in enumerate(indexs):
                code_result, code_input = (
                    code_results[result_index]["content"],
                    code_inputs[result_index],
                )
                code_result = deepcopy(code_result.replace("print(", "scan_to_print = ("))
                code_result = eval_function([code_result, code_input])
                outputs[inputs_index] = code_result
                if code_result[0] is not None:
                    flags[inputs_index] = False
                else:
                    if show_code and iter == iter_num - 1:
                        print(code_result)
                    # æ·»åŠ ä¿®æ­£ä¿¡æ¯è®©æ¨¡å‹å¯ä»¥ä¿®æ­£ä»£ç 
                    if inputs[inputs_index][-1]["role"] == "user":
                        inputs[inputs_index].append(
                            {
                                "role": "assistant",
                                "content": "```python" + code_result[1][1] + "\n```",
                            }
                        )
                        inputs[inputs_index].append(
                            {
                                "role": "user",
                                "content": "Your code generation contains an error. Please regenerate the code based on the following error message"
                                + code_result[1][0],
                            }
                        )
                    else:
                        initial_inputs = inputs[inputs_index][-1]
                        inputs[inputs_index] = inputs[inputs_index][:-1]
                        inputs[inputs_index].append(
                            {
                                "role": "assistant",
                                "content": "```python" + code_result[1][1] + "\n```",
                            }
                        )
                        inputs[inputs_index].append(
                            {
                                "role": "user",
                                "content": "Your code generation contains an error. Please regenerate the code based on the following error message"
                                + code_result[1][0],
                            }
                        )
                        inputs[inputs_index].append(initial_inputs)
            # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥æœªå®Œæˆ
            if any(flags):
                print("æœ‰%sæ¡æ•°æ®ç”Ÿæˆä»£ç å¤±è´¥" % sum(flags))
            else:
                print("æ‰€æœ‰ä»£ç éƒ½ç”ŸæˆæˆåŠŸ")
        return outputs, flags

    def extract_variable(self, dataset):
        """
        ä»æ•°æ®é›†ä¸­æå–å˜é‡å¹¶æ›´æ–°æ•°æ®é›†ã€‚

        è¯¥å‡½æ•°æ ¹æ®æä¾›çš„æç¤ºå­—å…¸ç”Ÿæˆä»£ç ï¼Œé€šè¿‡æ‰§è¡Œç”Ÿæˆçš„ä»£ç æ¥è¯†åˆ«å’Œæå–å˜é‡ï¼Œå¹¶å°†è¿™äº›å˜é‡æ·»åŠ å›åŸå§‹æ•°æ®é›†ä¸­ã€‚

        å‚æ•°:
        - dataset: åŒ…å«éœ€è¦æå–å˜é‡çš„é—®é¢˜çš„åˆ—è¡¨ã€‚
        - prompt: åŒ…å«ç”Ÿæˆä»£ç æ‰€éœ€æç¤ºçš„å­—å…¸ã€‚

        è¿”å›:
        - æ›´æ–°åçš„æ•°æ®é›†ï¼ŒåŒ…å«æå–åˆ°çš„å˜é‡ä¿¡æ¯ã€‚
        """
        # ç”Ÿæˆè¾“å…¥ä»£ç æ¨¡æ¿ï¼Œç”¨äºåç»­æ‰§è¡Œä»¥æå–å˜é‡
        inputs = [
            self.prompt["get_var_example"]
            + [
                {
                    "role": "user",
                    "content": self.prompt["get_var_prefix"] + t["question"],
                },
                self.prompt["get_var_prompt"],
            ]
            for t in dataset
        ]

        def eval_function(inputs):
            code_result, code_input = inputs
            """
            æ‰§è¡Œç”Ÿæˆçš„ä»£ç å¹¶æå–å˜é‡ã€‚

            æ­¤å‡½æ•°å°è¯•æ‰§è¡Œç”Ÿæˆçš„ä»£ç ç‰‡æ®µï¼Œå¹¶æ•è·æ‰§è¡Œè¿‡ç¨‹ä¸­å®šä¹‰çš„å˜é‡ã€‚

            å‚æ•°:
            - code_result: ç”Ÿæˆçš„ä»£ç ç»“æœå­—ç¬¦ä¸²ã€‚

            è¿”å›:
            - æˆåŠŸæ—¶è¿”å›ä»£ç å’Œæ•è·çš„å˜é‡åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›Noneã€‚
            """
            try:
                local_vars = {}
                code_result = "known_variables = {\n    " + code_result
                exec((code_result + "}"), {}, local_vars)
                known_variables = local_vars.get("known_variables")
                return [code_result + "}", known_variables]
            except Exception as e:
                if "is not defined" in str(e):
                    return [
                        None,
                        [
                            """For the dictionary known_variables, all keys must be of type str, and each value corresponding to the keys must be either of type float or int. Furthermore, no external variables should be called.
We found that your generated code has a key that calls an external variable when defining its value. Please modify it to a form that does not require calling an external variable. If this is not possible, you may remove this key.""",
                            code_result,
                        ],
                    ]
                return [None, [str(e), code_result]]

        # ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ä»¥æå–å˜é‡
        prefix = "```python\nknown_variables = {\n    "
        stop = "}"
        outputs, flags = self.generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        old_topp = self.code_topp
        for _ in range(5):
            if not any(flags):
                break
            print("å‘ç°%dæ¡æ•°æ®æ²¡èƒ½æˆåŠŸç”Ÿæˆä»£ç ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ" % sum(flags))
            self.code_topp = min(1, self.code_topp + 0.1)
            outputs, flags = self.generate_code(
                inputs,
                prefix=prefix,
                stop=stop,
                eval_function=eval_function,
                flags=flags,
                outputs=outputs,
            )
        self.code_topp = old_topp
        # æ›´æ–°æ•°æ®é›†ä»¥åŒ…å«æå–åˆ°çš„å˜é‡
        for i in range(len(outputs)):
            dataset[i]["known_variables"] = outputs[i][1]
            dataset[i]["known_variables_generate"] = outputs[i][0]

        return dataset

    def generate_solve_code(self, inputs, prompt):
        """
        ç”Ÿæˆå¹¶è¯„ä¼°ä»£ç è§£å†³æ–¹æ¡ˆï¼Œæ ¹æ®ç»™å®šçš„è¾“å…¥å’Œæç¤ºä¿¡æ¯ã€‚

        å‚æ•°:
        - inputs: é—®é¢˜çš„è¾“å…¥ä¿¡æ¯ï¼Œç”¨äºç”Ÿæˆä»£ç ã€‚
        - prompt: æç¤ºä¿¡æ¯ï¼ŒåŒ…å«å¦‚ä½•æ ¼å¼åŒ–è¾“å‡ºç»“æœçš„æ¨¡æ¿ã€‚

        è¿”å›:
        - exec_codes: ç”Ÿæˆçš„å¯æ‰§è¡Œä»£ç åˆ—è¡¨ã€‚
        - codes_responses: ä»£ç æ‰§è¡Œç»“æœçš„æ–‡æœ¬æè¿°åˆ—è¡¨ã€‚
        - param_inputs: è¾“å…¥å‚æ•°åˆ—è¡¨ã€‚
        - exec_results: ä»£ç æ‰§è¡Œç»“æœåˆ—è¡¨ã€‚
        """
        import_prefix = prompt["import_prefix"]

        def eval_function(inputs):
            """
            è¯„ä¼°ç”Ÿæˆçš„ä»£ç æ˜¯å¦æ­£ç¡®æ‰§è¡Œï¼Œå¹¶æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç‰¹å®šçš„å˜é‡ã€‚

            å‚æ•°:
            - inputs: åŒ…å«ç”Ÿæˆçš„ä»£ç å’ŒåŸå§‹è¾“å…¥ä¿¡æ¯çš„å…ƒç»„ã€‚

            è¿”å›:
            - å¦‚æœä»£ç ä¸­ç¼ºå°‘å˜é‡æˆ–å­˜åœ¨é”™è¯¯ï¼Œåˆ™è¿”å›é”™è¯¯ä¿¡æ¯å’ŒåŸå§‹ä»£ç ã€‚
            - å¦åˆ™ï¼Œè¿”å›æ ¼å¼åŒ–åçš„ä»£ç å’Œè¾“å…¥è¾“å‡ºå˜é‡ã€‚
            """
            code_result, code_input = deepcopy(inputs)
            local_vars = {}

            code_result = "\nparams_input = {\n    '" + code_result
            try:
                # å°è¯•æ‰§è¡Œæ ¼å¼åŒ–åçš„ä»£ç 
                execute(import_prefix + code_result, local_vars)
            except Exception as e:
                error = str(e)
                try:
                    eval(error)
                    return None, [
                        "Find a dict variable not have a key %s,but use it" % str(e),
                        code_result,
                    ]
                except:
                    pass
                try:
                    # å¦‚æœä¸Šè¿°å°è¯•å¤±è´¥ï¼Œåˆ™å°è¯•ç›´æ¥æ‰§è¡ŒåŸå§‹ä»£ç 
                    if "is not defined" in error:
                        prefix_code = ""
                        for t in code_input:
                            if "```python" in t["content"]:
                                matches = re.findall(
                                    r"```python(.*?)```", t["content"], re.DOTALL
                                )
                                code = matches[0]
                                while " known_variables = {" in code:
                                    code = code.replace(
                                        " known_variables = {", "known_variables = {"
                                    )
                        execute(
                            prefix_code + "\n" + import_prefix + code_result, local_vars
                        )
                        return None, [
                            "your code find a error call:"
                            + str(e)
                            + "\nThe generated code should be able to execute successfully without relying on external variables.",
                            code_result,
                        ]
                    elif "timed out" in error.lower():
                        return None, [
                            "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                            code_result,
                        ]
                    else:
                        execute(
                            import_prefix + code_result.replace("\n    ", "\n"),
                            local_vars,
                        )
                except Exception as e:
                    error = str(e)
                    if "is not defined" in error:
                        return None, [
                            "your code find a error call:"
                            + str(e)
                            + "\nThe generated code should be able to execute successfully without relying on external variables.",
                            code_result,
                        ]
                    elif "timed out" in error.lower():
                        return None, [
                            "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                            code_result,
                        ]
                    return None, ["your code find a error call:" + str(e), code_result]

            # ä»æ‰§è¡Œç»“æœä¸­æå–è¾“å…¥å‚æ•°å’Œè¾“å‡ºç»“æœ
            params_input = local_vars.get("params_input")
            output_result = local_vars.get("output_result")
            if output_result is None:
                return None, [
                    "This code does not have a 'output_result' variable to represent the function's output.You should add the 'output_result' variable in your code to represent the output variables of this problem.",
                    code_result,
                ]

            if not isinstance(output_result, dict):
                return None, [
                    "The variable 'output_result' should be a Python dict class variable",
                    code_result,
                ]

            if output_result is None:
                return None, [
                    "There is no 'output_result' variable in this code to represent the output of the function.",
                    code_result,
                ]
            try:
                for key, value in output_result.items():
                    assert type(value) != bool
                    if type(value) == str:
                        value = re.findall(r"-?\d+\.\d+|-?\d+", value)[0]
                    float(value)
                    output_result[key] = value
            except:
                return None, [
                    "For all values in the dictionary variable 'output_result', they should be either int or float variables. The value '%s' of key '%s' is not an int or float variable.The value's dtype is %s"
                    % (value, key, str(type(value).__name__)),
                    code_result,
                ]
            return [code_result, [params_input, output_result]]

        # ç”Ÿæˆå¯èƒ½çš„ä»£ç è§£å†³æ–¹æ¡ˆ
        prefix = "```python\nparams_input = {\n    '"
        code_results, flags = self.generate_code(
            inputs, prefix=prefix, eval_function=eval_function
        )
        old_topp = self.code_topp
        old_topk = self.code_topk
        for _ in range(3):
            if not any(flags):
                break
            print("å‘ç°%dæ¡æ•°æ®æ²¡èƒ½æˆåŠŸç”Ÿæˆä»£ç ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ" % sum(flags))
            self.code_topp = min(1, self.code_topp + 0.3)
            self.code_topk = min(max(64, old_topk), self.code_topk + 16)
            code_results, flags = self.generate_code(
                inputs,
                prefix=prefix,
                eval_function=eval_function,
                flags=flags,
                outputs=code_results,
            )

        if any(flags):
            print("Warning:æœ€ç»ˆå‘ç°%dæ¡æ•°æ®æ²¡èƒ½æˆåŠŸç”Ÿæˆä»£ç !!!!!" % sum(flags))

        self.code_topp = old_topp
        self.code_topk = old_topk
        exec_codes, codes_responses, param_inputs, exec_results = [], [], [], []
        for t in code_results:
            if t[0] is None:
                param_inputs.append(None)
                exec_results.append(None)
                exec_codes.append(None)
                codes_responses.append(None)
            else:
                param_input, exec_result = t[1]
                # æ ¼å¼åŒ–æ‰§è¡Œç»“æœä¸ºæ–‡æœ¬
                answers = list(exec_result.values())
                if len(answers) == 1:
                    answer = answers[0]
                else:
                    answer = ",".join([str(x) for x in answers])

                exec_result_sentence = prompt["exec_result_prompt"].format(
                    result=str(exec_result).replace("\\", ""), answer=answer
                )
                param_inputs.append(param_input)
                exec_results.append(exec_result)
                exec_codes.append(t[0])
                codes_responses.append(
                    "```python\n" + t[0] + "```\n" + exec_result_sentence
                )
        return exec_codes, codes_responses, param_inputs, exec_results

    def generate(self, model_inputs, flags, states, middle_results, n_action: int):
        """
        æ ¹æ®ä¸åŒçš„çŠ¶æ€ç”Ÿæˆç›¸åº”çš„è¾“å‡ºã€‚

        å‚æ•°:
        - model_inputs: æ¨¡å‹è¾“å…¥æ•°æ®ã€‚
        - flags: æ ‡å¿—æ•°ç»„ï¼ŒæŒ‡ç¤ºæ˜¯å¦åº”å¤„ç†ç›¸åº”çš„è¾“å…¥ã€‚
        - states: çŠ¶æ€æ•°ç»„ï¼Œå®šä¹‰äº†å½“å‰æ¯ä¸ªè¾“å…¥çš„çŠ¶æ€ã€‚
        - middle_results: ä¸­é—´ç»“æœæ•°ç»„ï¼Œç”¨äºå­˜å‚¨ç”Ÿæˆçš„è¾“å‡ºã€‚
        - n_action: åŠ¨ä½œæ•°é‡ï¼Œç”¨äºæ§åˆ¶ç”Ÿæˆçš„åŠ¨ä½œæ•°é‡ã€‚

        æ­¤å‡½æ•°æ ¹æ®è¾“å…¥çš„çŠ¶æ€ï¼Œå°†ç›¸åº”çš„è¾“å…¥æ•°æ®åˆ†é…åˆ°ä¸åŒçš„å¤„ç†åˆ†æ”¯ä¸­ï¼Œ
        å¹¶ç”Ÿæˆç›¸åº”çš„è¾“å‡ºï¼ŒåŒ…æ‹¬åŠ¨ä½œã€å¥–åŠ±ã€çŠ¶æ€å’Œé—®é¢˜ã€‚
        """
        # åˆå§‹åŒ–ä¸åŒçŠ¶æ€ä¸‹çš„è¾“å…¥æ•°æ®å’Œç´¢å¼•åˆ—è¡¨
        action_inputs, action_indexs = [], []
        step_inputs, step_indexs = [], []
        reward_inputs, reward_indexs = [], []
        question_inputs, question_indexs = [], []

        # éå†æ‰€æœ‰è¾“å…¥çŠ¶æ€ï¼Œæ ¹æ®çŠ¶æ€å¯¹è¾“å…¥è¿›è¡Œåˆ†ç±»
        for i in range(len(states)):
            if states[i] is None or flags[i] is False:
                # å¦‚æœçŠ¶æ€ä¸ºNoneæˆ–æ ‡å¿—ä¸ºFalseï¼Œåˆ™è·³è¿‡å½“å‰è¾“å…¥
                continue
            elif states[i] == "Search_End":
                # å¦‚æœçŠ¶æ€ä¸º'Search_End'ï¼Œåˆ™å°†å¯¹åº”æ ‡å¿—è®¾ä¸ºFalse
                flags[i] = False
            elif "end" in states[i].lower():
                # å¦‚æœçŠ¶æ€ä¸­åŒ…å«'end'ï¼Œåˆ™è·³è¿‡å½“å‰è¾“å…¥
                continue
            elif "fast_reward" == states[i]:
                # å¦‚æœçŠ¶æ€ä¸º'fast_reward'ï¼Œåˆ™å°†è¾“å…¥æ·»åŠ åˆ°reward_inputsä¸­
                reward_inputs.append(model_inputs[i])
                reward_indexs.append(i)
            elif "get_question" == states[i]:
                # å¦‚æœçŠ¶æ€ä¸º'get_question'ï¼Œåˆ™å°†è¾“å…¥æ·»åŠ åˆ°question_inputsä¸­
                question_inputs.append(model_inputs[i])
                question_indexs.append(i)
            elif "get_action" == states[i]:
                # å¦‚æœçŠ¶æ€ä¸º'get_action'ï¼Œåˆ™å°†è¾“å…¥æ·»åŠ åˆ°action_inputsä¸­
                action_inputs.append(model_inputs[i])
                action_indexs.append(i)
            elif "step" == states[i]:
                # å¦‚æœçŠ¶æ€ä¸º'step'ï¼Œåˆ™å°†è¾“å…¥æ·»åŠ åˆ°step_inputsä¸­
                step_inputs.append(model_inputs[i])
                step_indexs.append(i)

        # å¦‚æœæœ‰åŠ¨ä½œè¾“å…¥ï¼Œåˆ™ç”Ÿæˆç›¸åº”æ•°é‡çš„åŠ¨ä½œ
        if len(action_inputs) != 0:
            print("generate action")
            actions = self.chat_generate(action_inputs, n=n_action)
            actions = [t["content"] for t in actions]
            for i, index in enumerate(action_indexs):
                middle_results[index].action_outputs = actions[
                    i * n_action : (i + 1) * n_action
                ]

        # å¦‚æœæœ‰å¥–åŠ±è¾“å…¥ï¼Œåˆ™ç”Ÿæˆå¥–åŠ±
        if len(reward_inputs) != 0:
            print("generate rewards")
            logits = self.rewards_predict(reward_inputs)
            for i, index in enumerate(reward_indexs):
                middle_results[index].logits = logits[i]

        # å¦‚æœæœ‰æ­¥éª¤è¾“å…¥ï¼Œåˆ™ç”Ÿæˆæ­¥éª¤çŠ¶æ€
        if len(step_inputs) != 0:
            print("generate states")
            inputs = []
            for i, t in enumerate(step_inputs):
                inputs.extend(t)
            exec_codes, codes_responses, param_inputs, exec_results = (
                self.generate_solve_code(inputs, self.prompt)
            )
            outputs = [[] for i in range(len(step_inputs))]
            k = 0
            for i in range(len(step_inputs)):
                for j in range(len(step_inputs[i])):
                    outputs[i].append(
                        [
                            exec_codes[k],
                            codes_responses[k],
                            param_inputs[k],
                            exec_results[k],
                        ]
                    )
                    k += 1
            # outputs = np.array(outputs)
            for i, index in enumerate(step_indexs):
                middle_results[index].exec_code = [t[0] for t in outputs[i]]
                middle_results[index].step_outputs = [t[1] for t in outputs[i]]
                middle_results[index].para_input = [t[2] for t in outputs[i]]
                middle_results[index].para_output = [t[3] for t in outputs[i]]

        # å¦‚æœæœ‰é—®é¢˜è¾“å…¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è¡¨ç¤ºä¸æ”¯æŒæ­¤æ¨¡å¼
        if len(question_inputs) != 0:
            raise ("not support this mode")

        # æ¸…ç†åƒåœ¾å†…å­˜
        gc.collect()


class ChatCOTModel(ChatGenerateModel):
    def __init__(
        self,
        model_name,
        action_max_tokens=None,
        action_topp=0,
        action_topk=0,
        action_temperature=None,
        native_rewards_mode=True,
        Qmodel=None,
        Vmodel=None,
        evaluator=None,
        **kwargs,
    ):
        super().__init__(model_name=model_name, **kwargs)
        self.Qmodel = Qmodel
        self.Vmodel = Vmodel
        self.evaluator = evaluator
        self.use_Qmodel = True
        self.native_rewards_mode = native_rewards_mode
        self.model_name = model_name
        if action_max_tokens == None:
            action_max_tokens = self.max_tokens
        self.action_max_tokens = action_max_tokens
        if action_temperature == None:
            self.action_temperature = self.temperature
        else:
            self.action_temperature = action_temperature
        if action_topp == 0:
            self.action_topp = self.top_p
        else:
            self.action_topp = action_topp
        if action_topk == 0:
            self.action_topk = self.top_k
        else:
            self.action_topk = action_topk

    def generate_step(self, inputs: list) -> list:
        """
        æ ¹æ®è¾“å…¥æ•°æ®ç”Ÿæˆç›¸åº”çš„è¾“å‡ºæ­¥éª¤ã€‚

        è¯¥å‡½æ•°é¦–å…ˆå°†è¾“å…¥æ•°æ®åˆ†ä¸ºä¸¤ç±»ï¼šç‰¹æ®Šé—®é¢˜å’Œæ™®é€šé—®é¢˜ã€‚ç‰¹æ®Šé—®é¢˜æ˜¯ä»¥ç‰¹å®šå‰ç¼€å¼€å§‹çš„é—®é¢˜ï¼Œ
        è€Œæ™®é€šé—®é¢˜æ˜¯ä¸åŒ…å«è¯¥å‰ç¼€çš„å…¶ä»–é—®é¢˜ã€‚ç„¶åï¼Œé’ˆå¯¹è¿™ä¸¤ç±»é—®é¢˜åˆ†åˆ«è¿›è¡Œå¤„ç†å’Œç”Ÿæˆå›ç­”ã€‚
        æœ€åï¼Œå°†ç”Ÿæˆçš„å›ç­”æŒ‰ç…§åŸå§‹è¾“å…¥æ•°æ®çš„é¡ºåºè¿›è¡Œåˆå¹¶å’Œè¿”å›ã€‚

        å‚æ•°:
        inputs (list): åŒ…å«å¤šä¸ªé—®é¢˜åºåˆ—çš„åˆ—è¡¨ï¼Œæ¯ä¸ªé—®é¢˜åºåˆ—æ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œä»£è¡¨ä¸€æ¬¡å¯¹è¯å†å²ã€‚

        è¿”å›:
        list: åŒ…å«å¤šä¸ªå›ç­”åºåˆ—çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå›ç­”åºåˆ—æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä»£è¡¨ç”Ÿæˆçš„å›ç­”ã€‚
        """
        # åˆå§‹åŒ–æœ€ç»ˆå’Œæ™®é€šé—®é¢˜çš„ç´¢å¼•å’Œå†…å®¹åˆ—è¡¨
        finnal_indexs = []
        finnal_inputs = []
        normal_inputs = []
        normal_indexs = []

        # éå†è¾“å…¥æ•°æ®ï¼Œå¯¹æ¯ä¸ªå¯¹è¯å†å²è¿›è¡Œåˆ†ç±»
        for i, t in enumerate(inputs):
            # åˆ¤æ–­æ˜¯å¦ä¸ºç‰¹æ®Šé—®é¢˜
            if (
                self.prompt["overall_question_prefix"] in t[-1]["content"]
                and self.prompt["question_postfix"] == "**"
            ):
                if t[-1]["content"][-1] == "\n" and t[-1]["content"][-3:] != "**\n":
                    t[-1]["content"] = t[-1]["content"][:-1] + "**\n"
                finnal_inputs.append(t)
                finnal_indexs.append(i)
            else:
                normal_inputs.append(t)
                normal_indexs.append(i)

        # å¦‚æœæœ‰ç‰¹æ®Šé—®é¢˜ï¼Œè¿›è¡Œç‰¹æ®Šé—®é¢˜çš„å›ç­”ç”Ÿæˆ
        if len(finnal_inputs) != 0:
            final_outputs = self.chat_generate(finnal_inputs, stop=None)
            # å¯¹ç”Ÿæˆçš„å›ç­”è¿›è¡Œåå¤„ç†ï¼Œç§»é™¤åŸå§‹é—®é¢˜å†…å®¹
            for i in range(len(finnal_inputs)):
                final_outputs[i] = final_outputs[i]["content"].replace(
                    finnal_inputs[i][-1]["content"], ""
                )

        # å¦‚æœæœ‰æ™®é€šé—®é¢˜ï¼Œè¿›è¡Œæ™®é€šé—®é¢˜çš„å›ç­”ç”Ÿæˆ
        if len(normal_inputs) != 0:
            normal_outputs = self.chat_generate(normal_inputs, stop=self.stop)
            # å¯¹ç”Ÿæˆçš„å›ç­”è¿›è¡Œåå¤„ç†ï¼Œç§»é™¤åŸå§‹é—®é¢˜å†…å®¹å¹¶æ ¼å¼åŒ–è¾“å‡º
            for i in range(len(normal_outputs)):
                normal_outputs[i] = (
                    normal_outputs[i]["content"].replace(
                        normal_inputs[i][-1]["content"], ""
                    )
                    + "\n\n"
                )

        # åˆå§‹åŒ–æœ€ç»ˆè¾“å‡ºåˆ—è¡¨
        outputs = [[] for i in range(len(inputs))]

        # å°†æ™®é€šé—®é¢˜çš„å›ç­”æ”¾å…¥æœ€ç»ˆè¾“å‡ºåˆ—è¡¨çš„ç›¸åº”ä½ç½®
        for i, index in enumerate(normal_indexs):
            outputs[index] = normal_outputs[i]

        # å°†ç‰¹æ®Šé—®é¢˜çš„å›ç­”æ”¾å…¥æœ€ç»ˆè¾“å‡ºåˆ—è¡¨çš„ç›¸åº”ä½ç½®
        for i, index in enumerate(finnal_indexs):
            outputs[index] = final_outputs[i]

        # è¿”å›æœ€ç»ˆè¾“å‡ºåˆ—è¡¨
        return outputs

    def generate(self, model_inputs, flags, states, middle_results, n_action: int = 1):
        action_inputs, action_indexs = [], []
        step_inputs, step_indexs = [], []
        reward_inputs, reward_indexs = [], []
        question_inputs, question_indexs = [], []
        revise_inputs, revise_indexs = [], []
        for i in range(len(states)):
            if states[i] == None or flags[i] == False:
                continue
            elif states[i] == "Search_End":
                flags[i] = False
            elif "end" in states[i].lower():
                continue
            elif "fast_reward" == states[i]:
                reward_inputs.append(model_inputs[i])
                reward_indexs.append(i)
            elif "get_question" == states[i]:
                question_inputs.append(model_inputs[i])
                question_indexs.append(i)
            elif "get_action" == states[i]:
                action_inputs.append(model_inputs[i])
                action_indexs.append(i)
            elif "step" == states[i]:
                step_inputs.append(model_inputs[i])
                step_indexs.append(i)
            elif "revise" == states[i]:
                revise_inputs.append(model_inputs[i])
                revise_indexs.append(i)
        if len(action_inputs) != 0:
            print("generate action")
            actions = self.chat_generate(
                action_inputs,
                n=n_action,
                stop=self.prompt["question_postfix"],
                max_tokens=self.action_max_tokens,
                top_p=self.action_topp,
                top_k=self.action_topk,
                temperature=self.action_temperature,
            )
            for i, index in enumerate(action_indexs):
                action_outputs = actions[i * n_action : (i + 1) * n_action]
                middle_results[index].action_outputs = []
                for j in range(len(action_outputs)):
                    try:
                        action_outputs[j] = (
                            action_outputs[j]["content"].replace(
                                action_inputs[i][-1]["content"], ""
                            )
                            + self.prompt["question_postfix"]
                            + "\n"
                        )
                    except:
                        action_outputs[j] = ""
                    while "***" in action_outputs[j]:
                        action_outputs[j] = action_outputs[j].replace("***", "**")
                    if (
                        len(self.tokenizer.encode(action_outputs[j]))
                        < self.action_max_tokens - 10
                        and "ğŸŒˆ" not in action_outputs[j]
                    ):
                        middle_results[index].action_outputs.append(action_outputs[j])
        if len(reward_inputs) != 0:
            print("generate rewards")
            if self.native_rewards_mode or self.Qmodel == None:
                logits = self.rewards_predict(deepcopy(reward_inputs))
            else:
                assert self.Qmodel != None and self.Vmodel != None
                if self.use_Qmodel:
                    self.reward_model = self.Qmodel
                else:
                    self.reward_model = self.Vmodel
                logits = self.rewards_predict(deepcopy(reward_inputs))
                self.use_Qmodel = not self.use_Qmodel
            for i, index in enumerate(reward_indexs):
                middle_results[index].logits = logits[i]

        if len(step_inputs) != 0:
            print("generate states")
            inputs = []
            for i, t in enumerate(step_inputs):
                inputs.extend(t)
            steps = self.generate_step(inputs)
            outputs = [[] for i in range(len(step_inputs))]
            k = 0
            for i in range(len(step_inputs)):
                for j in range(len(step_inputs[i])):
                    outputs[i].append(steps[k])
                    k += 1
            for i, index in enumerate(step_indexs):
                middle_results[index].step_outputs = outputs[i]
        if len(revise_inputs) != 0:
            print("revise answer")
            inputs = []
            for i, t in enumerate(revise_inputs):
                inputs.extend(t)
            revise_outputs = self.chat_generate(
                inputs,
                n=1,
                stop=None,
                max_tokens=self.max_tokens,
                top_p=self.top_p,
                top_k=self.top_k,
                temperature=self.temperature,
            )
            outputs = [[] for i in range(len(revise_inputs))]
            k = 0
            for i in range(len(revise_inputs)):
                for j in range(len(revise_inputs[i])):
                    outputs[i].append(revise_outputs[k]["content"])
                    k += 1
            for i, index in enumerate(revise_indexs):
                middle_results[index].revise_result = outputs[i]
        if len(question_inputs) != 0:
            raise ("not support this mode")

    def rewards_predict(self, reward_inputs):
        if self.native_rewards_mode:
            return super().rewards_predict(reward_inputs)
        yes_inputs = []
        no_inputs = []
        indicis = []
        for i, nodes in enumerate(reward_inputs):
            for node in nodes:
                indicis.append(i)
                yes_inputs.append(node + self.select_tokens[0])
                no_inputs.append(node + self.select_tokens[1])
        yes_outputs = self.reward_model.generate(
            yes_inputs,
            SamplingParams(max_tokens=1, prompt_logprobs=20),
            use_tqdm=self.use_tqdm,
        )
        no_outputs = self.reward_model.generate(
            no_inputs,
            SamplingParams(max_tokens=1, prompt_logprobs=20),
            use_tqdm=self.use_tqdm,
        )
        logits_output = [[] for i in range(len(reward_inputs))]
        for i, result in enumerate(no_outputs):
            try:
                logits = [
                    self.get_logis(
                        yes_outputs[i].prompt_logprobs[-1], self.select_token_id[0]
                    ),
                    self.get_logis(
                        no_outputs[i].prompt_logprobs[-1], self.select_token_id[1]
                    ),
                ]
            except:
                logits = [-1e9, 1]
            logits_output[indicis[i]].append(logits)

        return logits_output


class ChatCodeModel(ChatCOTModel):
    def extract_variable(self, dataset, initial_prompt):
        inputs = []
        inital_example = []
        for t in initial_prompt["interactive_examples"]:
            inital_example.extend(t)
        for t in dataset:
            inputs.append(
                inital_example
                + [
                    initial_prompt["instruction"],
                    {"role": "user", "content": t["question"]},
                    {"role": "assistant", "content": initial_prompt["answer_prefix"]},
                ]
            )

        def eval_function(inputs):
            code_result, code_input = inputs
            code_result = code_result.replace("```python", "")
            """
            æ‰§è¡Œç”Ÿæˆçš„ä»£ç å¹¶æå–å˜é‡ã€‚

            æ­¤å‡½æ•°å°è¯•æ‰§è¡Œç”Ÿæˆçš„ä»£ç ç‰‡æ®µï¼Œå¹¶æ•è·æ‰§è¡Œè¿‡ç¨‹ä¸­å®šä¹‰çš„å˜é‡ã€‚

            å‚æ•°:
            - code_result: ç”Ÿæˆçš„ä»£ç ç»“æœå­—ç¬¦ä¸²ã€‚

            è¿”å›:
            - æˆåŠŸæ—¶è¿”å›ä»£ç å’Œæ•è·çš„å˜é‡åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å›Noneã€‚
            """
            try:
                local_vars = {}
                execute(code_result, local_vars)
                return [
                    code_result,
                    code_result.replace(initial_prompt["answer_prefix"], ""),
                ]
            except Exception as e:
                if "= None" in code_result:
                    return [
                        code_result,
                        [
                            "The defined variable should not be assigned to None",
                            code_result,
                        ],
                    ]
                return [None, [str(e), code_result]]

        prefix = ""
        stop = initial_prompt["stop_token"]
        outputs, flags = super(ChatCodeModel, self).generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        old_topp = self.code_topp
        old_topk = self.code_topk
        for _ in range(5):
            if not any(flags):
                break
            print("å‘ç°%dæ¡æ•°æ®æ²¡èƒ½æˆåŠŸç”Ÿæˆä»£ç ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ" % sum(flags))
            self.code_topp = min(1, self.code_topp + 0.1)
            self.code_topk = self.code_topk + 16
            outputs, flags = super().generate_code(
                inputs,
                prefix=prefix,
                stop=stop,
                eval_function=eval_function,
                flags=flags,
                outputs=outputs,
            )
        self.code_topp = old_topp
        self.code_topk = old_topk

        inital_variable = [{"inital_variable": t[0]} for t in outputs]
        return inital_variable

    def generate_step(self, inputs: list) -> list:
        """
        æ ¹æ®è¾“å…¥æ•°æ®ç”Ÿæˆç›¸åº”çš„è¾“å‡ºæ­¥éª¤ã€‚

        è¯¥å‡½æ•°é¦–å…ˆå°†è¾“å…¥æ•°æ®åˆ†ä¸ºä¸¤ç±»ï¼šç‰¹æ®Šé—®é¢˜å’Œæ™®é€šé—®é¢˜ã€‚ç‰¹æ®Šé—®é¢˜æ˜¯ä»¥ç‰¹å®šå‰ç¼€å¼€å§‹çš„é—®é¢˜ï¼Œ
        è€Œæ™®é€šé—®é¢˜æ˜¯ä¸åŒ…å«è¯¥å‰ç¼€çš„å…¶ä»–é—®é¢˜ã€‚ç„¶åï¼Œé’ˆå¯¹è¿™ä¸¤ç±»é—®é¢˜åˆ†åˆ«è¿›è¡Œå¤„ç†å’Œç”Ÿæˆå›ç­”ã€‚
        æœ€åï¼Œå°†ç”Ÿæˆçš„å›ç­”æŒ‰ç…§åŸå§‹è¾“å…¥æ•°æ®çš„é¡ºåºè¿›è¡Œåˆå¹¶å’Œè¿”å›ã€‚

        å‚æ•°:
        inputs (list): åŒ…å«å¤šä¸ªé—®é¢˜åºåˆ—çš„åˆ—è¡¨ï¼Œæ¯ä¸ªé—®é¢˜åºåˆ—æ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œä»£è¡¨ä¸€æ¬¡å¯¹è¯å†å²ã€‚

        è¿”å›:
        list: åŒ…å«å¤šä¸ªå›ç­”åºåˆ—çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå›ç­”åºåˆ—æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä»£è¡¨ç”Ÿæˆçš„å›ç­”ã€‚
        """
        # åˆå§‹åŒ–æœ€ç»ˆå’Œæ™®é€šé—®é¢˜çš„ç´¢å¼•å’Œå†…å®¹åˆ—è¡¨
        finnal_indexs = []
        finnal_inputs = []
        normal_inputs = []
        normal_indexs = []

        # éå†è¾“å…¥æ•°æ®ï¼Œå¯¹æ¯ä¸ªå¯¹è¯å†å²è¿›è¡Œåˆ†ç±»
        for i, t in enumerate(inputs):
            # åˆ¤æ–­æ˜¯å¦ä¸ºç‰¹æ®Šé—®é¢˜
            if (
                self.prompt["overall_question_prefix"][:-1].lower()
                in t[-1]["content"].lower()
            ):
                finnal_inputs.append(t)
                finnal_indexs.append(i)
            else:
                normal_inputs.append(t)
                normal_indexs.append(i)

        # å¦‚æœæœ‰ç‰¹æ®Šé—®é¢˜ï¼Œè¿›è¡Œç‰¹æ®Šé—®é¢˜çš„å›ç­”ç”Ÿæˆ
        if len(finnal_inputs) != 0:
            final_outputs = self.generate_code(finnal_inputs, stop="```")
            # å¯¹ç”Ÿæˆçš„å›ç­”è¿›è¡Œåå¤„ç†ï¼Œç§»é™¤åŸå§‹é—®é¢˜å†…å®¹
            for i in range(len(finnal_inputs)):
                final_outputs[i] = final_outputs[i]["content"].replace(
                    finnal_inputs[i][-1]["content"], ""
                )

        # å¦‚æœæœ‰æ™®é€šé—®é¢˜ï¼Œè¿›è¡Œæ™®é€šé—®é¢˜çš„å›ç­”ç”Ÿæˆ
        if len(normal_inputs) != 0:
            normal_outputs = self.generate_code(normal_inputs, stop=self.stop + ["```"])
            # å¯¹ç”Ÿæˆçš„å›ç­”è¿›è¡Œåå¤„ç†ï¼Œç§»é™¤åŸå§‹é—®é¢˜å†…å®¹å¹¶æ ¼å¼åŒ–è¾“å‡º
            for i in range(len(normal_outputs)):
                normal_outputs[i] = (
                    normal_outputs[i]["content"].replace(
                        normal_inputs[i][-1]["content"], ""
                    )
                    + "\n\n"
                )

        # åˆå§‹åŒ–æœ€ç»ˆè¾“å‡ºåˆ—è¡¨
        outputs = [[] for i in range(len(inputs))]

        # å°†æ™®é€šé—®é¢˜çš„å›ç­”æ”¾å…¥æœ€ç»ˆè¾“å‡ºåˆ—è¡¨çš„ç›¸åº”ä½ç½®
        for i, index in enumerate(normal_indexs):
            outputs[index] = normal_outputs[i]

        # å°†ç‰¹æ®Šé—®é¢˜çš„å›ç­”æ”¾å…¥æœ€ç»ˆè¾“å‡ºåˆ—è¡¨çš„ç›¸åº”ä½ç½®
        for i, index in enumerate(finnal_indexs):
            outputs[index] = final_outputs[i]

        # è¿”å›æœ€ç»ˆè¾“å‡ºåˆ—è¡¨
        return outputs

    def generate_code(self, inputs, stop, iter_num=5):
        def eval_function(inputs):
            code_result, code_input = inputs
            code_result = code_input[-1]["content"] + code_result.replace(
                code_input[-1]["content"], ""
            ).replace("```python", "").replace(
                "\n" + self.prompt["overall_question_prefix"],
                "\n#" + self.prompt["overall_question_prefix"],
            ).replace("##", "#")

            try:
                local_vars = {}
                execute(code_result, local_vars)
                if (
                    self.prompt["overall_question_prefix"] in code_result
                    and local_vars.get("result") == None
                ):
                    return [
                        None,
                        [
                            'The "%s" appears in the code, indicating that the problem should be solved. You should follow the requirements of the system and write the result into a result variable. But there is no such result variable in your code.'
                            % self.prompt["overall_question_prefix"],
                            code_result,
                        ],
                    ]

                code = code_result.replace(code_input[-1]["content"], "")
                execute_result = ""
                flag = True
                for name, value in local_vars.items():
                    if name in code:
                        flag = False
                        execute_result += "%s:%s(%s);" % (
                            str(name),
                            str(value),
                            str(type(value)),
                        )
                execute_result = (
                    '\n"""The running status of existing variables:\n%s\n"""\n'
                    % execute_result
                )
                if flag:
                    return [code_result, code_result]
                return [code_result + execute_result, code_result + execute_result]
            except Exception as e:
                return [None, [str(e), code_result]]

        prefix = ""
        outputs, flags = super(ChatCodeModel, self).generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        old_topp = self.code_topp
        old_topk = self.code_topk
        for iter in range(iter_num):
            if not any(flags):
                break
            print("å‘ç°%dæ¡æ•°æ®æ²¡èƒ½æˆåŠŸç”Ÿæˆä»£ç ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ" % sum(flags))
            self.code_topp = min(1, self.code_topp + 0.1)
            self.code_topk = self.code_topk + old_topk
            outputs, flags = super().generate_code(
                inputs,
                prefix=prefix,
                stop=stop,
                show_code=iter == iter_num - 1,
                eval_function=eval_function,
                flags=flags,
                outputs=outputs,
            )
        self.code_topp = old_topp
        self.code_topk = old_topk
        for i in range(len(outputs)):
            outputs[i] = outputs[i][0]
            if outputs[i] != None:
                outputs[i] = outputs[i].replace(inputs[i][-1]["content"], "")
                while "\n\n\n" in outputs[i]:
                    outputs[i] = outputs[i].replace("\n\n\n", "\n\n")
            else:
                outputs[i] = (
                    "\n#This question was not successfully answered, please correct it and propose a new, more reasonable question.\n"
                )
        return [{"content": outputs[i]} for i in range(len(outputs))]


class PRMChatCOTModel(ChatCOTModel):
    def __init__(
        self,
        model_name,
        reward_model_name,
        reward_model_gpu_memory_utilization,
        reward_token="<extra_0>",
        native_rewards_mode=False,
        **kwargs,
    ):
        super().__init__(
            model_name=model_name, native_rewards_mode=native_rewards_mode, **kwargs
        )
        if native_rewards_mode == False:
            self.reward_token = reward_token
            self.reward_model = LLM(
                model=reward_model_name,
                gpu_memory_utilization=reward_model_gpu_memory_utilization,
                trust_remote_code=True,
                max_model_len=kwargs["max_model_len"],
                task="reward",
                enable_prefix_caching=True,
            )

    def rewards_predict(self, reward_inputs):
        if self.native_rewards_mode:
            for i in range(len(reward_inputs)):
                reward_inputs[i] = [
                    self.prompt["useful_examples_prefix"]
                    % (t[-2]["content"], t[-1]["content"])
                    for t in reward_inputs[i]
                ]
            return super().rewards_predict(reward_inputs)
        inputs = []
        indicis = []
        for i, nodes in enumerate(reward_inputs):
            for node in nodes:
                indicis.append(i)
                inputs.append(
                    self.tokenizer.apply_chat_template(
                        node, tokenize=False, add_generation_prompt=True
                    )[:-11]
                    + self.reward_token
                )
        reward_outputs = self.reward_model.encode(
            inputs,
            use_tqdm=self.use_tqdm,
        )
        logits_output = [[] for i in range(len(reward_inputs))]
        for i, result in enumerate(reward_outputs):
            reward = result.outputs.data.numpy()[0]
            logits = np.log(reward)[::-1]
            logits_output[indicis[i]].append(logits)
        return logits_output


class DeepMCTSModel(PRMChatCOTModel):
    def generate_step(self, inputs: list) -> list:
        """
        æ ¹æ®è¾“å…¥æ•°æ®ç”Ÿæˆç›¸åº”çš„è¾“å‡ºæ­¥éª¤ã€‚

        è¯¥å‡½æ•°é¦–å…ˆå°†è¾“å…¥æ•°æ®åˆ†ä¸ºä¸¤ç±»ï¼šç‰¹æ®Šé—®é¢˜å’Œæ™®é€šé—®é¢˜ã€‚ç‰¹æ®Šé—®é¢˜æ˜¯ä»¥ç‰¹å®šå‰ç¼€å¼€å§‹çš„é—®é¢˜ï¼Œ
        è€Œæ™®é€šé—®é¢˜æ˜¯ä¸åŒ…å«è¯¥å‰ç¼€çš„å…¶ä»–é—®é¢˜ã€‚ç„¶åï¼Œé’ˆå¯¹è¿™ä¸¤ç±»é—®é¢˜åˆ†åˆ«è¿›è¡Œå¤„ç†å’Œç”Ÿæˆå›ç­”ã€‚
        æœ€åï¼Œå°†ç”Ÿæˆçš„å›ç­”æŒ‰ç…§åŸå§‹è¾“å…¥æ•°æ®çš„é¡ºåºè¿›è¡Œåˆå¹¶å’Œè¿”å›ã€‚

        å‚æ•°:
        inputs (list): åŒ…å«å¤šä¸ªé—®é¢˜åºåˆ—çš„åˆ—è¡¨ï¼Œæ¯ä¸ªé—®é¢˜åºåˆ—æ˜¯ä¸€ä¸ªå­—å…¸åˆ—è¡¨ï¼Œä»£è¡¨ä¸€æ¬¡å¯¹è¯å†å²ã€‚

        è¿”å›:
        list: åŒ…å«å¤šä¸ªå›ç­”åºåˆ—çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå›ç­”åºåˆ—æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä»£è¡¨ç”Ÿæˆçš„å›ç­”ã€‚
        """
        # åˆå§‹åŒ–æœ€ç»ˆå’Œæ™®é€šé—®é¢˜çš„ç´¢å¼•å’Œå†…å®¹åˆ—è¡¨
        finnal_indexs = []
        finnal_inputs = []
        normal_inputs = []
        normal_indexs = []
        code_inputs = []
        code_indexs = []
        # éå†è¾“å…¥æ•°æ®ï¼Œå¯¹æ¯ä¸ªå¯¹è¯å†å²è¿›è¡Œåˆ†ç±»
        for i, mopdel_input in enumerate(inputs):
            t, action = mopdel_input
            # åˆ¤æ–­æ˜¯å¦ä¸ºç‰¹æ®Šé—®é¢˜
            if action in self.prompt["summar_prompt"]:
                finnal_inputs.append(t)
                finnal_indexs.append(i)
            elif action in self.prompt["code_actions"]:
                code_inputs.append(t)
                code_indexs.append(i)
            else:
                normal_inputs.append(t)
                normal_indexs.append(i)

        # å¦‚æœæœ‰ç‰¹æ®Šé—®é¢˜ï¼Œè¿›è¡Œç‰¹æ®Šé—®é¢˜çš„å›ç­”ç”Ÿæˆ
        if len(finnal_inputs) != 0:
            print("summary step")
            final_outputs = self.chat_generate(
                finnal_inputs, stop=None, prefix=self.prompt["prefix"]
            )
            # å¯¹ç”Ÿæˆçš„å›ç­”è¿›è¡Œåå¤„ç†ï¼Œç§»é™¤åŸå§‹é—®é¢˜å†…å®¹
            for i in range(len(finnal_inputs)):
                final_outputs[i] = final_outputs[i]["content"].replace(
                    finnal_inputs[i][-1]["content"], ""
                )

        # å¦‚æœæœ‰æ™®é€šé—®é¢˜ï¼Œè¿›è¡Œæ™®é€šé—®é¢˜çš„å›ç­”ç”Ÿæˆ
        if len(normal_inputs) != 0:
            print("normal  step")
            normal_outputs = self.chat_generate(
                normal_inputs,
                stop=self.prompt["stop"].replace("\n", ""),
                prefix=self.prompt["prefix"],
            )
            # å¯¹ç”Ÿæˆçš„å›ç­”è¿›è¡Œåå¤„ç†ï¼Œç§»é™¤åŸå§‹é—®é¢˜å†…å®¹å¹¶æ ¼å¼åŒ–è¾“å‡º
            for i in range(len(normal_outputs)):
                normal_outputs[i] = (
                    normal_outputs[i]["content"].replace(
                        normal_inputs[i][-1]["content"], ""
                    )
                    + "\n"
                    + self.prompt["stop"]
                )
        if len(code_inputs) != 0:
            print("code step")
            code_outputs = self.generate_code(code_inputs)
        # åˆå§‹åŒ–æœ€ç»ˆè¾“å‡ºåˆ—è¡¨
        outputs = [[] for i in range(len(inputs))]

        # å°†æ™®é€šé—®é¢˜çš„å›ç­”æ”¾å…¥æœ€ç»ˆè¾“å‡ºåˆ—è¡¨çš„ç›¸åº”ä½ç½®
        for i, index in enumerate(normal_indexs):
            outputs[index] = normal_outputs[i]

        # å°†ç‰¹æ®Šé—®é¢˜çš„å›ç­”æ”¾å…¥æœ€ç»ˆè¾“å‡ºåˆ—è¡¨çš„ç›¸åº”ä½ç½®
        for i, index in enumerate(finnal_indexs):
            outputs[index] = final_outputs[i]

        for i, index in enumerate(code_indexs):
            outputs[index] = code_outputs[i]
        # è¿”å›æœ€ç»ˆè¾“å‡ºåˆ—è¡¨
        return outputs

    def generate_code(self, inputs):
        prefix = self.prompt["code_prefix"]
        stop = "```"

        def eval_function(inputs):
            code_result, code_input = inputs
            code = code_result.replace(code_input[-1]["content"], "")
            try:
                local_vars = {}
                execute(code, local_vars)
                execute_result = ""
                flag = True
                for name, value in local_vars.items():
                    if name in code and str(type(value)) != "<class 'function'>":
                        flag = False
                        execute_result += "%s:%s(%s);" % (
                            str(name),
                            str(value),
                            str(type(value)),
                        )
                if flag:
                    execute_result = "\nThis  code execute fail\n"
                else:
                    execute_result = (
                        "\nThe running status of existing variables:\n%s\n"
                        % execute_result
                    )
                code_result = (
                    prefix + code + "\n" + self.prompt["code_stop"] + execute_result
                )
                return [code_result, code_result]
            except Exception as e:
                return [None, [str(e), code]]

        outputs, flags = super(DeepMCTSModel, self).generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        for i in range(len(outputs)):
            if not flags[i]:
                outputs[i] = outputs[i][0]
                while "\n\n\n" in outputs[i]:
                    outputs[i] = outputs[i].replace("\n\n\n", "\n\n")
            else:
                outputs[i] = outputs[i][1][-1]
        return outputs


# 1å’Œ2çš„åŒºåˆ«æ˜¯æˆ‘åœ¨ä»£ç é‡ŒåŠ äº†è¶…æ—¶promptï¼Œå…¶ä»–æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œéš¾é¢˜ç»å¸¸ä¼šå†™æ­»å¾ªç¯ï¼Œæ‰€ä»¥è¦åŠ ä¸Šè¿™ä¸ª
class DeepMCTSModel2(DeepMCTSModel):
    def generate_code(self, inputs):
        prefix = self.prompt["code_prefix"]
        stop = "```"

        def eval_function(inputs):
            code_result, code_input = inputs
            code = code_result.replace(code_input[-1]["content"], "")
            try:
                local_vars = {}
                execute(code, local_vars)
                execute_result = ""
                flag = True
                for name, value in local_vars.items():
                    if name in code and str(type(value)) != "<class 'function'>":
                        flag = False
                        execute_result += "%s:%s(%s);" % (
                            str(name),
                            str(value),
                            str(type(value)),
                        )
                if flag:
                    execute_result = "\nThis  code execute fail\n"
                else:
                    execute_result = (
                        "\nThe running status of existing variables:\n%s\n"
                        % execute_result
                    )
                code_result = (
                    prefix + code + "\n" + self.prompt["code_stop"] + execute_result
                )
                return [code_result, code_result]
            except Exception as e:
                if "timed out" in str(e).lower():
                    return None, [
                        "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                        code_result,
                    ]
                return [None, [str(e), code]]

        outputs, flags = super(DeepMCTSModel, self).generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        for i in range(len(outputs)):
            if not flags[i]:
                outputs[i] = outputs[i][0]
                while "\n\n\n" in outputs[i]:
                    outputs[i] = outputs[i].replace("\n\n\n", "\n\n")
            else:
                outputs[i] = outputs[i][1][-1]
        return outputs


codes = []


class DeepMCTSModel3(DeepMCTSModel):
    def generate_code(self, inputs):
        prefix = self.prompt["code_prefix"]
        stop = "```"

        def eval_function(inputs):
            global codes
            code_result, code_input = inputs
            code = code_result.replace(code_input[-1]["content"], "")

            if "jax" in code or "tensorflow" in code:
                return None, [
                    "Your code should not use neural network libraries like JAX or TensorFlow.",
                    code_result,
                ]
            elif "matplotlib" in code:
                return None, [
                    "The visualization code of matplotlib is of no help in solving this problem. Please write a new code. Don't use the matplotlib library.",
                    code_result,
                ]
            try:
                local_vars = {}
                execute(code, local_vars)
                codes.append(code)
                execute_result = ""
                flag = True
                for name, value in local_vars.items():
                    value_type = str(type(value))
                    old_type = type(value)
                    if (
                        name in code
                        and value_type != "<class 'function'>"
                        and "<class 'module'>" not in value_type
                    ):
                        flag = False
                        if "float" in value_type:
                            value = round(value, 4)
                        if (
                            "list" in value_type
                            or "tuple" in value_type
                            or "array" in value_type
                        ):
                            try:
                                value = np.array(value)
                                value = old_type(value)(np.round_(value, 4))
                            except:
                                if "list" in value_type:
                                    value = [
                                        round(x, 4) if isinstance(x, float) else x
                                        for x in value
                                    ]
                                elif "tuple" in value_type:
                                    value = tuple(
                                        [
                                            round(x, 4) if isinstance(x, float) else x
                                            for x in value
                                        ]
                                    )
                        execute_result += "%s:%s;" % (str(name), str(value))
                if flag:
                    execute_result = "\nThis  code execute fail\n"
                else:
                    execute_result = (
                        "\nThe running status of existing variables:\n%s\n"
                        % execute_result
                    )
                code_result = (
                    prefix + code + "\n" + self.prompt["code_stop"] + execute_result
                )
                return [code_result, code_result]
            except Exception as e:
                if "is not defined" in str(e).lower():
                    return None, [
                        "your code find a error call:"
                        + str(e)
                        + "\nThe generated code should be able to execute successfully without relying on external variables.If you have used these variables before, please rewrite them again.",
                        code_result,
                    ]

                if "timed out" in str(e).lower():
                    return None, [
                        "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                        code_result,
                    ]
                return [None, [str(e), code]]

        outputs, flags = super(DeepMCTSModel, self).generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        for i in range(len(outputs)):
            if not flags[i]:
                outputs[i] = outputs[i][0]
                while "\n\n\n" in outputs[i]:
                    outputs[i] = outputs[i].replace("\n\n\n", "\n\n")
            else:
                outputs[i] = (
                    outputs[i][1][-1] + "This code find error:\n" + outputs[i][1][0]
                )
        return outputs

    def rewards_predict(self, reward_inputs):
        # ä¸»è¦æ˜¯åŠ äº†ä¸ªé•¿åº¦é™åˆ¶ï¼Œä¸ç„¶ä¼šç‚¸
        if self.native_rewards_mode:
            return super().rewards_predict(reward_inputs)
        inputs = []
        indicis = []
        for i, nodes in enumerate(reward_inputs):
            for node in nodes:
                indicis.append(i)
                token = self.tokenizer.apply_chat_template(
                    node, tokenize=False, add_generation_prompt=True
                )[:-11]
                token = self.tokenizer.decode(
                    self.tokenizer.encode(token)[-self.max_model_len + 3 :]
                )
                inputs.append(token + self.reward_token)
        reward_outputs = self.reward_model.encode(
            inputs,
            use_tqdm=self.use_tqdm,
        )
        logits_output = [[] for i in range(len(reward_inputs))]
        for i, result in enumerate(reward_outputs):
            reward = result.outputs.data.numpy()[0]
            logits = np.log(reward)[::-1]
            logits_output[indicis[i]].append(logits)
        return logits_output


import multiprocessing


def execute_code(code):
    local_vars = {}
    exec(code, local_vars)
    local_vars.pop("__builtins__")
    pop_list = []
    for key, value in local_vars.items():
        if "<function" in str(value) or "<module" in str(value):
            pop_list.append(key)
    for key in pop_list:
        local_vars.pop(key)
    return local_vars


def run_with_timeout(code, timeout=1):
    pool = multiprocessing.Pool(processes=1)
    try:
        result = pool.apply_async(execute_code, (code,))
        return result.get(timeout=timeout)
    except multiprocessing.TimeoutError:
        pool.terminate()
        raise TimeoutError
    finally:
        pool.close()
        pool.join()


class DeepMCTSModel4(DeepMCTSModel3):
    def generate_code(self, inputs):
        prefix = self.prompt["code_prefix"]
        stop = "```"

        def eval_function(inputs):
            global codes
            code_result, code_input = inputs
            code = code_result.replace(code_input[-1]["content"], "")

            if "jax" in code or "tensorflow" in code:
                return None, [
                    "Your code should not use neural network libraries like JAX or TensorFlow.",
                    code_result,
                ]
            elif "matplotlib" in code:
                return None, [
                    "The visualization code of matplotlib is of no help in solving this problem. Please write a new code. Don't use the matplotlib library.",
                    code_result,
                ]
            try:
                local_vars = run_with_timeout(code, timeout=2)
                codes.append(code)
                execute_result = ""
                flag = True
                for name, value in local_vars.items():
                    value_type = str(type(value))
                    old_type = type(value)
                    if (
                        name in code
                        and value_type != "<class 'function'>"
                        and "<class 'module'>" not in value_type
                    ):
                        flag = False
                        if "float" in value_type:
                            value = round(value, 4)
                        if (
                            "list" in value_type
                            or "tuple" in value_type
                            or "array" in value_type
                        ):
                            try:
                                value = np.array(value)
                                value = old_type(value)(np.round_(value, 4))
                            except:
                                if "list" in value_type:
                                    value = [
                                        round(x, 4) if isinstance(x, float) else x
                                        for x in value
                                    ]
                                elif "tuple" in value_type:
                                    value = tuple(
                                        [
                                            round(x, 4) if isinstance(x, float) else x
                                            for x in value
                                        ]
                                    )
                        execute_result += "%s:%s;" % (str(name), str(value))
                if flag:
                    execute_result = "\nThis  code execute fail\n"
                else:
                    execute_result = (
                        "\nThe running status of existing variables:\n%s\n"
                        % execute_result
                    )
                code_result = (
                    prefix + code + "\n" + self.prompt["code_stop"] + execute_result
                )
                return [code_result, code_result]
            except TimeoutError:
                if "sympy" in code:
                    return None, [
                        "Please ensure that all sympy calculations can be completed within 2 seconds, and the number of polynomials should not exceed 6.",
                        code_result,
                    ]
                return None, [
                    "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                    code_result,
                ]
            except Exception as e:
                if "is not defined" in str(e).lower():
                    return None, [
                        "your code find a error call:"
                        + str(e)
                        + "\nThe generated code should be able to execute successfully without relying on external variables.If you have used these variables before, please rewrite them again.",
                        code_result,
                    ]

                if "timed out" in str(e).lower():
                    return None, [
                        "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                        code_result,
                    ]
                return [None, [str(e), code]]

        outputs, flags = super(DeepMCTSModel, self).generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        for i in range(len(outputs)):
            if not flags[i]:
                outputs[i] = outputs[i][0]
                while "\n\n\n" in outputs[i]:
                    outputs[i] = outputs[i].replace("\n\n\n", "\n\n")
            else:
                outputs[i] = (
                    outputs[i][1][-1] + "This code find error:\n" + outputs[i][1][0]
                )
        return outputs

class DeepMCTSModel5(DeepMCTSModel3):
    def generate_code(self, inputs):
        prefix = self.prompt["code_prefix"]
        stop = "```"

        def eval_function(inputs):
            global codes
            code_result, code_input = inputs
            code = code_result.replace(code_input[-1]["content"], "")

            if "jax" in code or "tensorflow" in code:
                return None, [
                    "Your code should not use neural network libraries like JAX or TensorFlow.",
                    code_result,
                ]
            elif "matplotlib" in code:
                return None, [
                    "The visualization code of matplotlib is of no help in solving this problem. Please write a new code. Don't use the matplotlib library.",
                    code_result,
                ]
            try:
                local_vars = run_with_timeout(code, timeout=2)
                codes.append(code)
                execute_result = ""
                flag = True
                for name, value in local_vars.items():
                    value_type = str(type(value))
                    old_type = type(value)
                    if (
                        name in code
                        and value_type != "<class 'function'>"
                        and "<class 'module'>" not in value_type
                    ):
                        flag = False
                        if "float" in value_type:
                            value = round(value, 4)
                        if (
                            "list" in value_type
                            or "tuple" in value_type
                            or "array" in value_type
                        ):
                            try:
                                value = np.array(value)
                                value = old_type(value)(np.round_(value, 4))
                            except:
                                if "list" in value_type:
                                    value = [
                                        round(x, 4) if isinstance(x, float) else x
                                        for x in value
                                    ]
                                elif "tuple" in value_type:
                                    value = tuple(
                                        [
                                            round(x, 4) if isinstance(x, float) else x
                                            for x in value
                                        ]
                                    )
                        execute_result += "%s:%s;" % (str(name), str(value))
                if flag:
                    execute_result = "\nThis  code execute fail\n"
                else:
                    execute_result = (
                        "\nThe running status of existing variables:\n%s\n"
                        % execute_result
                    )
                code_result = (
                    prefix + code + "\n" + self.prompt["code_stop"] + execute_result
                )
                return [code_result, code_result]
            except TimeoutError:
                if "sympy" in code:
                    return None, [
                        "Please ensure that all sympy calculations can be completed within 2 seconds, and the number of polynomials should not exceed 6.",
                        code_result,
                    ]
                return None, [
                    "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                    code_result,
                ]
            except Exception as e:
                if "is not defined" in str(e).lower():
                    return None, [
                        "your code find a error call:"
                        + str(e)
                        + "\nThe generated code should be able to execute successfully without relying on external variables.If you have used these variables before, please rewrite them again.",
                        code_result,
                    ]

                if "timed out" in str(e).lower():
                    return None, [
                        "Your code may contain an infinite loop. Please modify your code. Try to avoid using a while loop; you can change it to a for loop or use Python libraries like math, sympy, or scipy to solve your problem.",
                        code_result,
                    ]
                return [None, [str(e), code]]

        outputs, flags = super(DeepMCTSModel, self).generate_code(
            inputs, prefix=prefix, stop=stop, eval_function=eval_function
        )
        for i in range(len(outputs)):
            if not flags[i]:
                outputs[i] = outputs[i][0]
                while "\n\n\n" in outputs[i]:
                    outputs[i] = outputs[i].replace("\n\n\n", "\n\n")
            else:
                outputs[i] = (
                    outputs[i][1][-1] + "This code find error:\n" + outputs[i][1][0]
                )
        return outputs
